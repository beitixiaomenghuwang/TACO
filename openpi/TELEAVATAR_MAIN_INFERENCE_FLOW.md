# Teleavatar Main.py æ¨ç†æ§åˆ¶æµç¨‹è¯¦è§£

## ğŸ“‹ æ¦‚è§ˆ

æ‚¨ä½¿ç”¨ä¸¤ä¸ªè„šæœ¬è¿è¡Œ Teleavatar æœºå™¨äººï¼š

1. **ç­–ç•¥æœåŠ¡å™¨**ï¼š`uv run scripts/serve_policy.py policy:checkpoint --policy.config=pi0_teleavatar_low_mem_finetune --policy.dir=pi0_teleavatar_low_mem_finetune/pi0_lora_with_joint_positions_and_gripper_efforts/29999`
2. **æœºå™¨äººå®¢æˆ·ç«¯**ï¼š`python examples/teleavatar/main.py --remote-host 192.168.1.100`

---

## ğŸ”§ é…ç½®å‚æ•°è¯¦è§£

### é»˜è®¤å‚æ•°ï¼ˆmain.py Argsï¼‰

```python
control_frequency: float = 20.0      # æ§åˆ¶å¾ªç¯é¢‘ç‡ 20Hz
action_horizon: int = 8              # ç­–ç•¥è¿”å›çš„åŠ¨ä½œåºåˆ—é•¿åº¦ï¼ˆæœªä½¿ç”¨ï¼‰
open_loop_horizon: int = 4           # æ‰§è¡Œ4ä¸ªåŠ¨ä½œåé‡æ–°æ¨ç†
prompt: str = "pick a toy..."        # è¯­è¨€æŒ‡ä»¤
num_episodes: int = 1                # è¿è¡Œ1ä¸ªepisode
max_episode_steps: int = 600         # æ¯ä¸ªepisodeæœ€å¤š600æ­¥
```

### ç­–ç•¥é…ç½®ï¼ˆpi0_teleavatar_low_mem_finetuneï¼‰

```python
# src/openpi/training/config.py:843-870
model = pi0_config.Pi0Config(
    paligemma_variant="gemma_2b_lora",
    action_expert_variant="gemma_300m_lora",
    action_dim=32,                   # æ¨¡å‹è¾“å‡º32ç»´åŠ¨ä½œ
    action_horizon=50                # æ¨¡å‹é»˜è®¤è¿”å›50æ­¥çš„åŠ¨ä½œåºåˆ—ï¼
)
```

**å…³é”®å‘ç°**ï¼š`action_horizon` é»˜è®¤ä¸º **50**ï¼ˆæœªåœ¨é…ç½®ä¸­æ˜¾å¼è®¾ç½®æ—¶ä½¿ç”¨é»˜è®¤å€¼ï¼‰

---

## ğŸ”„ å®Œæ•´æ¨ç†æ§åˆ¶æµç¨‹

### ç¬¬1æ­¥ï¼šåˆå§‹åŒ– (main.py:84-115)

```python
# 1. åˆ›å»º WebSocket å®¢æˆ·ç«¯è¿æ¥åˆ°ç­–ç•¥æœåŠ¡å™¨
ws_client_policy = WebsocketClientPolicy(
    host="192.168.1.100",  # æ‚¨çš„è¿œç¨‹ä¸»æœº
    port=8000
)

# 2. åˆ›å»º Teleavatar ç¯å¢ƒï¼ˆROS2æ¥å£ï¼‰
environment = TeleavatarEnvironment(prompt="pick a toy...")

# 3. åˆ›å»ºä»£ç†ï¼ŒåŒ…è£…äº† ActionChunkBroker
agent = PolicyAgent(
    policy=ActionChunkBroker(
        policy=ws_client_policy,
        action_horizon=4  # open_loop_horizon=4
    )
)

# 4. åˆ›å»ºè¿è¡Œæ—¶
runtime = Runtime(
    environment=environment,
    agent=agent,
    max_hz=20.0,         # 20Hz æ§åˆ¶å¾ªç¯
    num_episodes=1,
    max_episode_steps=600
)
```

### ç¬¬2æ­¥ï¼šè¿è¡Œæ—¶å¾ªç¯ (runtime.py)

```python
# runtime.run() -> _run_episode() -> _step() å¾ªç¯

def _step(self):
    # 2.1 è·å–è§‚æµ‹ï¼ˆ20Hzï¼‰
    observation = environment.get_observation()
    # è¿”å›: {
    #   'observation/state': [48],              # æœºå™¨äººçŠ¶æ€
    #   'observation/images/left_color': [480,848,3],
    #   'observation/images/right_color': [480,848,3],
    #   'observation/images/head_camera': [1080,1920,3],
    #   'prompt': "pick a toy..."
    # }
    
    # 2.2 è·å–åŠ¨ä½œï¼ˆé€šè¿‡ agentï¼‰
    action = agent.get_action(observation)
    
    # 2.3 åº”ç”¨åŠ¨ä½œåˆ°æœºå™¨äºº
    environment.apply_action(action)
    
    # 2.4 ä¿æŒ 20Hz é¢‘ç‡
    # æ¯ 50ms æ‰§è¡Œä¸€æ¬¡å¾ªç¯
```

### ç¬¬3æ­¥ï¼šåŠ¨ä½œè·å–æµç¨‹ï¼ˆæ ¸å¿ƒï¼ï¼‰

#### 3.1 PolicyAgent.get_action()

```python
# policy_agent.py:14
def get_action(self, observation: dict) -> dict:
    return self._policy.infer(observation)
    # è¿™é‡Œçš„ _policy æ˜¯ ActionChunkBroker
```

#### 3.2 ActionChunkBroker.infer()ï¼ˆå…³é”®é€»è¾‘ï¼‰

```python
# action_chunk_broker.py:27-44
def infer(self, obs: Dict) -> Dict:
    # ç¬¬ä¸€æ¬¡è°ƒç”¨æˆ–è€…åŠ¨ä½œç”¨å®Œäº†ï¼Ÿ
    if self._last_results is None:
        # âœ… å‘èµ·ç½‘ç»œæ¨ç†ï¼
        self._last_results = self._policy.infer(obs)
        # æœåŠ¡å™¨è¿”å›: {"actions": [50, 16]}  <-- 50ä¸ªæ—¶é—´æ­¥ï¼Œæ¯ä¸ª16ç»´
        self._cur_step = 0
    
    # ä»åŠ¨ä½œåºåˆ—ä¸­æå–å½“å‰æ­¥çš„åŠ¨ä½œ
    def slicer(x):
        if isinstance(x, np.ndarray):
            return x[self._cur_step, ...]  # å–ç¬¬ cur_step ä¸ªåŠ¨ä½œ
        else:
            return x
    
    results = tree.map_structure(slicer, self._last_results)
    # è¿”å›: {"actions": [16]}  <-- å•æ­¥åŠ¨ä½œ
    
    self._cur_step += 1
    
    # å·²ç»æ‰§è¡Œäº† action_horizon(4) ä¸ªåŠ¨ä½œï¼Ÿ
    if self._cur_step >= self._action_horizon:  # >= 4
        self._last_results = None  # æ¸…ç©ºï¼Œä¸‹æ¬¡ä¼šé‡æ–°æ¨ç†
    
    return results
```

#### 3.3 WebsocketClientPolicy.infer()

```python
# websocket_client_policy.py:44-51
def infer(self, obs: Dict) -> Dict:
    # åºåˆ—åŒ–è§‚æµ‹æ•°æ®
    data = self._packer.pack(obs)
    
    # å‘é€åˆ°æœåŠ¡å™¨
    self._ws.send(data)
    
    # æ¥æ”¶æœåŠ¡å™¨å“åº”
    response = self._ws.recv()
    
    # è§£åŒ…è¿”å›
    return msgpack_numpy.unpackb(response)
    # è¿”å›: {"actions": [50, 16]}
```

### ç¬¬4æ­¥ï¼šæœåŠ¡å™¨ç«¯æ¨ç† (serve_policy.py)

```python
# websocket_policy_server.py (ç®€åŒ–ç‰ˆæœ¬)
def handle_client(self, connection):
    while True:
        # æ¥æ”¶è§‚æµ‹
        obs_data = connection.recv()
        obs = msgpack_numpy.unpackb(obs_data)
        
        # è°ƒç”¨ç­–ç•¥æ¨ç†
        action = self._policy.infer(obs)
        # ç­–ç•¥è¿”å›: {"actions": [50, 16]}
        
        # å‘é€å›å®¢æˆ·ç«¯
        response = msgpack_numpy.packb(action)
        connection.send(response)
```

---

## ğŸ“Š å…³é”®æ•°æ®æµåˆ†æ

### è§‚æµ‹æ•°æ® (Environment â†’ Agent)

```
TeleavatarEnvironment.get_observation()
â†“
{
    'observation/state': np.ndarray[48],           # 48ç»´çŠ¶æ€
        # å¸ƒå±€ï¼š
        # [0:7]   å·¦è‡‚å…³èŠ‚ä½ç½®
        # [7:8]   å·¦è‡‚å¤¹çˆªå…³èŠ‚ä½ç½®
        # [8:15]  å³è‡‚å…³èŠ‚ä½ç½®
        # [15:16] å³è‡‚å¤¹çˆªå…³èŠ‚ä½ç½®
        # [16:23] å·¦è‡‚å…³èŠ‚é€Ÿåº¦
        # [23:24] å·¦è‡‚å¤¹çˆªé€Ÿåº¦
        # [24:31] å³è‡‚å…³èŠ‚é€Ÿåº¦
        # [31:32] å³è‡‚å¤¹çˆªé€Ÿåº¦
        # [32:39] å·¦è‡‚å…³èŠ‚åŠ›çŸ©
        # [39:40] å·¦è‡‚å¤¹çˆªåŠ›çŸ©
        # [40:47] å³è‡‚å…³èŠ‚åŠ›çŸ©
        # [47:48] å³è‡‚å¤¹çˆªåŠ›çŸ©
    
    'observation/images/left_color': np.ndarray[480, 848, 3],
    'observation/images/right_color': np.ndarray[480, 848, 3],
    'observation/images/head_camera': np.ndarray[1080, 1920, 3],
    'prompt': "pick a toy and put it in the basket using left gripper"
}
```

### ç­–ç•¥è¾“å‡º (Server â†’ Client)

```
WebsocketPolicyServer.policy.infer(obs)
â†“
{
    'actions': np.ndarray[50, 16]  # 50ä¸ªæ—¶é—´æ­¥ï¼Œæ¯ä¸ª16ç»´
        # 16ç»´åŠ¨ä½œå¸ƒå±€ï¼š
        # [0:7]   å·¦è‡‚å…³èŠ‚ä½ç½®ç›®æ ‡
        # [7:8]   å·¦è‡‚å¤¹çˆªåŠ›çŸ©ç›®æ ‡
        # [8:15]  å³è‡‚å…³èŠ‚ä½ç½®ç›®æ ‡
        # [15:16] å³è‡‚å¤¹çˆªåŠ›çŸ©ç›®æ ‡
}
```

### ActionChunkBroker è¾“å‡º (Agent â†’ Environment)

```
ActionChunkBroker.infer(obs)
â†“
{
    'actions': np.ndarray[16]  # å•æ­¥16ç»´åŠ¨ä½œ
}
```

---

## â±ï¸ æ—¶åºåˆ†æ

### æ—¶é—´çº¿ï¼ˆä»¥ 20Hz æ§åˆ¶ä¸ºä¾‹ï¼‰

```
æ—¶åˆ»    æ­¥æ•°    åŠ¨ä½œ                  æ¨ç†?    ç½‘ç»œè¯·æ±‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
0ms     0      actions[0] from chunk 0   âœ…       âœ…
50ms    1      actions[1] from chunk 0   âŒ       âŒ
100ms   2      actions[2] from chunk 0   âŒ       âŒ
150ms   3      actions[3] from chunk 0   âŒ       âŒ
200ms   4      actions[0] from chunk 1   âœ…       âœ…  <-- é‡æ–°æ¨ç†
250ms   5      actions[1] from chunk 1   âŒ       âŒ
300ms   6      actions[2] from chunk 1   âŒ       âŒ
350ms   7      actions[3] from chunk 1   âŒ       âŒ
400ms   8      actions[0] from chunk 2   âœ…       âœ…  <-- é‡æ–°æ¨ç†
...
```

### æ¨ç†é¢‘ç‡è®¡ç®—

- **æ§åˆ¶é¢‘ç‡**ï¼š20 Hz
- **å¼€ç¯æ­¥æ•°**ï¼š4 æ­¥
- **æ¨ç†é¢‘ç‡**ï¼š20 Hz Ã· 4 = **5 Hz** (æ¯ç§’æ¨ç†5æ¬¡)
- **ç½‘ç»œè¯·æ±‚é—´éš”**ï¼š200 ms

### åŠ¨ä½œåºåˆ—åˆ©ç”¨ç‡

- **æœåŠ¡å™¨è¿”å›**ï¼š50 ä¸ªåŠ¨ä½œï¼ˆshape: [50, 16]ï¼‰
- **å®é™…ä½¿ç”¨**ï¼š4 ä¸ªåŠ¨ä½œ
- **åˆ©ç”¨ç‡**ï¼š4/50 = **8%**

---

## ğŸ” è¯¦ç»†ä»£ç æ‰§è¡Œç¤ºä¾‹

### å®Œæ•´çš„4æ­¥å¾ªç¯

```python
# ===== ç¬¬1æ­¥ (0ms) =====
# runtime._step() è°ƒç”¨
observation = environment.get_observation()  # è·å–ä¼ æ„Ÿå™¨æ•°æ®

# agent.get_action(observation)
#   â†’ ActionChunkBroker.infer(observation)
#       â†’ _last_results is None, éœ€è¦æ¨ç†!
#       â†’ WebsocketClientPolicy.infer(observation)
#           â†’ å‘é€è§‚æµ‹åˆ°æœåŠ¡å™¨
#           â†’ æœåŠ¡å™¨æ¨ç†ï¼šè¿”å› {"actions": [50, 16]}
#       â†’ _last_results = {"actions": [50, 16]}
#       â†’ _cur_step = 0
#       â†’ è¿”å› actions[0] â†’ {"actions": [16]}
#       â†’ _cur_step = 1

action = {"actions": actions[0]}  # [16] ç»´
environment.apply_action(action)  # å‘é€åˆ°æœºå™¨äºº
# ç­‰å¾… 50ms


# ===== ç¬¬2æ­¥ (50ms) =====
observation = environment.get_observation()

# agent.get_action(observation)
#   â†’ ActionChunkBroker.infer(observation)
#       â†’ _last_results ä¸ä¸ºç©ºï¼Œä½¿ç”¨ç¼“å­˜
#       â†’ è¿”å› actions[1] â†’ {"actions": [16]}
#       â†’ _cur_step = 2

action = {"actions": actions[1]}
environment.apply_action(action)
# ç­‰å¾… 50ms


# ===== ç¬¬3æ­¥ (100ms) =====
observation = environment.get_observation()

# agent.get_action(observation)
#   â†’ ActionChunkBroker.infer(observation)
#       â†’ è¿”å› actions[2]
#       â†’ _cur_step = 3

action = {"actions": actions[2]}
environment.apply_action(action)
# ç­‰å¾… 50ms


# ===== ç¬¬4æ­¥ (150ms) =====
observation = environment.get_observation()

# agent.get_action(observation)
#   â†’ ActionChunkBroker.infer(observation)
#       â†’ è¿”å› actions[3]
#       â†’ _cur_step = 4
#       â†’ _cur_step (4) >= _action_horizon (4)
#       â†’ _last_results = None  # æ¸…ç©ºç¼“å­˜

action = {"actions": actions[3]}
environment.apply_action(action)
# ç­‰å¾… 50ms


# ===== ç¬¬5æ­¥ (200ms) =====
# é‡å¤ç¬¬1æ­¥çš„æµç¨‹ï¼Œå†æ¬¡å‘èµ·ç½‘ç»œæ¨ç†ï¼
```

---

## ğŸ¯ å…³é”®é—®é¢˜å›ç­”

### Q1: è¾“å‡ºçš„ action åŒ…å«å¤šå°‘æ¡åºåˆ—ï¼Ÿ

**åˆ†å±‚å›ç­”**ï¼š

1. **æœåŠ¡å™¨ç«¯æ¨ç†è¾“å‡º**ï¼š
   - è¿”å› `[50, 16]` çš„åŠ¨ä½œå¼ é‡
   - 50 ä¸ªæ—¶é—´æ­¥ï¼Œæ¯ä¸ª 16 ç»´åŠ¨ä½œ

2. **ActionChunkBroker è¾“å‡º**ï¼š
   - æ¯æ¬¡è¿”å› `[16]` çš„å•æ­¥åŠ¨ä½œ
   - ä» 50 æ­¥åºåˆ—ä¸­æŒ‰é¡ºåºæå–

3. **å®é™…ä½¿ç”¨**ï¼š
   - æ¯æ¬¡æ¨ç†ä½¿ç”¨å‰ 4 æ­¥
   - å 46 æ­¥è¢«ä¸¢å¼ƒï¼ˆåˆ©ç”¨ç‡ 8%ï¼‰

### Q2: æ˜¯åªè¿›è¡Œä¸€æ¬¡æ¨ç†è¿˜æ˜¯æ‰§è¡Œå‡ æ­¥åå†æ¬¡æ¨ç†ï¼Ÿ

**ç­”æ¡ˆ**ï¼š**æ‰§è¡Œ 4 æ­¥åå†æ¬¡æ¨ç†**

- **æœºåˆ¶**ï¼šActionChunkBroker å®ç°äº†åŠ¨ä½œç¼“å­˜
- **ç¼“å­˜å¤§å°**ï¼š`open_loop_horizon = 4`
- **æ¨ç†è§¦å‘æ¡ä»¶**ï¼š

  ```python
  if self._cur_step >= self._action_horizon:  # >= 4
      self._last_results = None  # è§¦å‘ä¸‹æ¬¡æ¨ç†
  ```

### Q3: æ¨ç†é¢‘ç‡æ˜¯å¤šå°‘ï¼Ÿ

- **æ§åˆ¶å¾ªç¯**ï¼š20 Hzï¼ˆæ¯ 50ms ä¸€æ­¥ï¼‰
- **æ¨ç†é¢‘ç‡**ï¼š5 Hzï¼ˆæ¯ 200ms ä¸€æ¬¡ï¼‰
- **æ•ˆç‡æå‡**ï¼šæ¯”æ¯æ­¥æ¨ç†å¿« **4å€**

---

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### å½“å‰ä½æ•ˆé—®é¢˜

```
æœåŠ¡å™¨è¿”å›: [50, 16] = 800ä¸ªæµ®ç‚¹æ•°
å®é™…ä½¿ç”¨:   [4, 16]  = 64ä¸ªæµ®ç‚¹æ•°
æµªè´¹æ¯”ä¾‹:   92%
```

### ä¼˜åŒ–æ–¹æ¡ˆ1ï¼šè°ƒæ•´æœåŠ¡å™¨ action_horizon

ä¿®æ”¹ `config.py`ï¼š

```python
TrainConfig(
    name="pi0_teleavatar_low_mem_finetune",
    model=pi0_config.Pi0Config(
        action_horizon=4,  # æ”¹ä¸º4ï¼ŒåŒ¹é… open_loop_horizon
        action_dim=32
    ),
    ...
)
```

### ä¼˜åŒ–æ–¹æ¡ˆ2ï¼šå¢åŠ  open_loop_horizon

ä¿®æ”¹ `main.py`ï¼š

```python
open_loop_horizon: int = 10  # ä½¿ç”¨æ›´å¤šç¼“å­˜åŠ¨ä½œ
```

**æƒè¡¡**ï¼š

- âœ… å‡å°‘æ¨ç†æ¬¡æ•°ï¼Œæé«˜æ•ˆç‡
- âŒ å¼€ç¯æ§åˆ¶æ—¶é—´æ›´é•¿ï¼Œå¯èƒ½å½±å“ååº”é€Ÿåº¦

### ä¼˜åŒ–æ–¹æ¡ˆ3ï¼šåŠ¨æ€è°ƒæ•´ï¼ˆæ¨èï¼‰

```python
# æ ¹æ®ä»»åŠ¡å¤æ‚åº¦åŠ¨æ€è°ƒæ•´
if task_requires_precision:
    open_loop_horizon = 2  # æ›´é¢‘ç¹çš„é—­ç¯åé¦ˆ
else:
    open_loop_horizon = 8  # æ›´é«˜æ•ˆçš„å¼€ç¯æ‰§è¡Œ
```

---

## ğŸ“ˆ ä¸ DROID å¯¹æ¯”

| æŒ‡æ ‡               | Teleavatar (å½“å‰) | DROID          |
|-------------------|------------------|----------------|
| æ§åˆ¶é¢‘ç‡           | 20 Hz           | 15 Hz          |
| å¼€ç¯æ­¥æ•°           | 4               | 8              |
| æ¨ç†é¢‘ç‡           | 5 Hz            | 1.875 Hz       |
| æœåŠ¡å™¨è¾“å‡ºé•¿åº¦     | 50              | 15             |
| åŠ¨ä½œåˆ©ç”¨ç‡         | 8% (4/50)       | 53.3% (8/15)   |
| åŠ¨ä½œç»´åº¦           | 16              | 8              |
| ç½‘ç»œè¯·æ±‚é—´éš”       | 200ms           | 533ms          |

**åˆ†æ**ï¼š

- Teleavatar æ¨ç†æ›´é¢‘ç¹ï¼ˆæ›´åŠæ—¶çš„åé¦ˆï¼‰
- DROID åˆ©ç”¨ç‡æ›´é«˜ï¼ˆæ›´é«˜æ•ˆçš„èµ„æºä½¿ç”¨ï¼‰

---

## ğŸ”¬ è°ƒè¯•æŠ€å·§

### æ·»åŠ æ—¥å¿—æŸ¥çœ‹æ¨ç†æ—¶æœº

åœ¨ `action_chunk_broker.py` ä¸­ï¼š

```python
def infer(self, obs: Dict) -> Dict:
    if self._last_results is None:
        print(f"ğŸ”„ [æ¨ç†] å‘èµ·æ–°çš„æ¨ç†è¯·æ±‚...")
        self._last_results = self._policy.infer(obs)
        self._cur_step = 0
        print(f"   æ”¶åˆ°åŠ¨ä½œåºåˆ—: {self._last_results['actions'].shape}")
    
    results = tree.map_structure(slicer, self._last_results)
    print(f"ğŸ“¤ [æ­¥{self._cur_step}] ä½¿ç”¨ç¼“å­˜åŠ¨ä½œ {self._cur_step}/{self._action_horizon}")
    self._cur_step += 1
    
    if self._cur_step >= self._action_horizon:
        print(f"âœ… [å®Œæˆ] åŠ¨ä½œåºåˆ—ç”¨å®Œï¼Œä¸‹æ¬¡å°†é‡æ–°æ¨ç†")
        self._last_results = None
    
    return results
```

### éªŒè¯åŠ¨ä½œåºåˆ—é•¿åº¦

åœ¨ `main.py` ä¸­ï¼š

```python
metadata = ws_client_policy.get_server_metadata()
print(f"æœåŠ¡å™¨é…ç½®: {metadata}")
# åº”è¯¥åŒ…å« action_horizon ä¿¡æ¯
```

---

## ğŸ“ æ€»ç»“

### æ ¸å¿ƒæµç¨‹

1. **20Hz æ§åˆ¶å¾ªç¯**ï¼šæ¯ 50ms è·å–è§‚æµ‹å¹¶æ‰§è¡Œä¸€ä¸ªåŠ¨ä½œ
2. **5Hz æ¨ç†é¢‘ç‡**ï¼šæ¯ 4 æ­¥ï¼ˆ200msï¼‰è¯·æ±‚ä¸€æ¬¡æ–°çš„åŠ¨ä½œåºåˆ—
3. **åŠ¨ä½œç¼“å­˜æœºåˆ¶**ï¼šæœåŠ¡å™¨è¿”å› 50 æ­¥ï¼Œå®¢æˆ·ç«¯ä½¿ç”¨å‰ 4 æ­¥
4. **å¼€ç¯æ‰§è¡Œ**ï¼šåœ¨ç¼“å­˜çš„ 4 æ­¥å†…ä¸è€ƒè™‘æ–°çš„ä¼ æ„Ÿå™¨åé¦ˆ

### å…³é”®ç»„ä»¶èŒè´£

- **Runtime**ï¼šç»´æŠ¤ 20Hz æ§åˆ¶å¾ªç¯
- **ActionChunkBroker**ï¼šç®¡ç†åŠ¨ä½œç¼“å­˜ï¼Œå†³å®šä½•æ—¶æ¨ç†
- **WebsocketClientPolicy**ï¼šä¸æœåŠ¡å™¨é€šä¿¡
- **TeleavatarEnvironment**ï¼šROS2 æ¥å£ï¼Œè¯»ä¼ æ„Ÿå™¨å†™åŠ¨ä½œ

### æ€§èƒ½ç‰¹ç‚¹

- âœ… é™ä½ç½‘ç»œå»¶è¿Ÿå½±å“ï¼ˆæ‰¹é‡è·å–åŠ¨ä½œï¼‰
- âœ… å‡å°‘æ¨ç†æ¬¡æ•°ï¼ˆ5Hz vs 20Hzï¼‰
- âš ï¸ åŠ¨ä½œåºåˆ—åˆ©ç”¨ç‡ä½ï¼ˆ8%ï¼‰
- âš ï¸ å¼€ç¯æ‰§è¡Œå¯èƒ½å½±å“ç²¾åº¦

---

*ç”Ÿæˆæ—¶é—´ï¼š2025-10-17*
*åŸºäºï¼šopenpi @ commit gxy branch*
